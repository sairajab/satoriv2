/s/chromatin/p/nobackup/Saira/original/satori/data/Arabidopsis_ChromAccessibility/atAll_m200_s600 36
Loaded model for finetunig...
Epoch :  1
Train Results (Loss and AUC):  0.5102833817297213 0.7255975658962323
Best Validation Loss: 0.515 and AUC: 0.72 

Epoch-1 lr: 0.0001 valid_loss: 0.5150203075207455
Epoch :  2
Train Results (Loss and AUC):  0.5101943564358813 0.7257836095237769
Epoch-2 lr: 0.0001 valid_loss: 0.5170110927221361
Epoch :  3
Train Results (Loss and AUC):  0.5096862196079833 0.726496805261529
Best Validation Loss: 0.511 and AUC: 0.73 

Epoch-3 lr: 0.0001 valid_loss: 0.5114312935882891
Epoch :  4
Train Results (Loss and AUC):  0.5096144327637163 0.726431574079417
Epoch-4 lr: 0.0001 valid_loss: 0.5127921112826173
Epoch :  5
Train Results (Loss and AUC):  0.5093659550056862 0.7270910181077146
Epoch-5 lr: 0.0001 valid_loss: 0.5155323006457566
Epoch :  6
Train Results (Loss and AUC):  0.5091519399652492 0.7272788669774546
Epoch-6 lr: 0.0001 valid_loss: 0.5184988198985516
Epoch :  7
Train Results (Loss and AUC):  0.5089536498797655 0.7276938610988294
Epoch-7 lr: 0.0001 valid_loss: 0.5141587076892316
Epoch :  8
Train Results (Loss and AUC):  0.5086316893884234 0.7283433096624214
Epoch-8 lr: 0.0001 valid_loss: 0.528146034954859
Epoch :  9
Train Results (Loss and AUC):  0.5086053306208342 0.7281840474295505
Best Validation Loss: 0.511 and AUC: 0.73 

Epoch-9 lr: 0.0001 valid_loss: 0.5113746327973308
Epoch :  10
Train Results (Loss and AUC):  0.5082852496415622 0.7283904024495436
Epoch-10 lr: 0.0001 valid_loss: 0.5122495409748364
Epoch :  11
Train Results (Loss and AUC):  0.5078536412109335 0.7293603205824151
Epoch-11 lr: 0.0001 valid_loss: 0.5118653285951121
Epoch :  12
Train Results (Loss and AUC):  0.5074657064514811 0.7295785205834776
Epoch-12 lr: 0.0001 valid_loss: 0.5119562044110096
Epoch :  13
Train Results (Loss and AUC):  0.507323419212312 0.7300576878786597
Epoch-13 lr: 0.0001 valid_loss: 0.5308679630498931
Epoch :  14
Train Results (Loss and AUC):  0.5073435387636663 0.7304299548177088
Epoch-14 lr: 0.0001 valid_loss: 0.5216988515406148
Epoch :  15
Train Results (Loss and AUC):  0.5074894109168238 0.7302574450847243
Epoch-15 lr: 1e-05 valid_loss: 0.5251550631064205
Epoch :  16
Train Results (Loss and AUC):  0.5065229035238215 0.7314700996036381
Best Validation Loss: 0.510 and AUC: 0.73 

Epoch-16 lr: 1e-05 valid_loss: 0.5095298421774672
Epoch :  17
Train Results (Loss and AUC):  0.5066797049152275 0.7312571446623626
Epoch-17 lr: 1e-05 valid_loss: 0.5103399336617878
Epoch :  18
Train Results (Loss and AUC):  0.5061862729884711 0.7317711235041542
Best Validation Loss: 0.509 and AUC: 0.73 

Epoch-18 lr: 1e-05 valid_loss: 0.5091260366596526
Epoch :  19
Train Results (Loss and AUC):  0.5064892615109367 0.7314230230895995
Epoch-19 lr: 1e-05 valid_loss: 0.5099918572275851
Epoch :  20
Train Results (Loss and AUC):  0.5064092826436069 0.7315552984543546
Epoch-20 lr: 1e-05 valid_loss: 0.5101719606370433
Epoch :  21
Train Results (Loss and AUC):  0.5064400964196074 0.7317369840702693
Epoch-21 lr: 1e-05 valid_loss: 0.5100189192754002
Epoch :  22
Train Results (Loss and AUC):  0.506545844151078 0.7316034095108543
Epoch-22 lr: 1e-05 valid_loss: 0.5115849361733091
Epoch :  23
Train Results (Loss and AUC):  0.5062301935029114 0.731765539155603
Best Validation Loss: 0.509 and AUC: 0.73 

Epoch-23 lr: 1e-05 valid_loss: 0.5090833996103403
Epoch :  24
Train Results (Loss and AUC):  0.5063810429598333 0.7319697870376083
Epoch-24 lr: 1.0000000000000002e-06 valid_loss: 0.5110327129912489
Epoch :  25
Train Results (Loss and AUC):  0.506214673513518 0.7314505597446126
Epoch-25 lr: 1.0000000000000002e-06 valid_loss: 0.5093792444663429
Epoch :  26
Train Results (Loss and AUC):  0.5060278339787563 0.732058641879339
Epoch-26 lr: 1.0000000000000002e-06 valid_loss: 0.5094274905086124
Epoch :  27
Train Results (Loss and AUC):  0.5059609864218637 0.7319910644187729
Epoch-27 lr: 1.0000000000000002e-06 valid_loss: 0.5094206026742156
Epoch :  28
Train Results (Loss and AUC):  0.5060064188512953 0.7320401235826748
Epoch-28 lr: 1.0000000000000002e-06 valid_loss: 0.5095323763542892
Epoch :  29
Train Results (Loss and AUC):  0.5063486740572293 0.7319734440007708
Epoch-29 lr: 1.0000000000000002e-06 valid_loss: 0.5095106561978658
Epoch :  30
Train Results (Loss and AUC):  0.5060652589559275 0.7320410604678517
Epoch-30 lr: 1.0000000000000002e-07 valid_loss: 0.5095245278497257
Epoch :  31
Train Results (Loss and AUC):  0.5062525424364739 0.7317521413527219
Epoch-31 lr: 1.0000000000000002e-07 valid_loss: 0.5095218807598795
Epoch :  32
Train Results (Loss and AUC):  0.5060507189328876 0.732130801568705
Epoch-32 lr: 1.0000000000000002e-07 valid_loss: 0.5095313530013035
Epoch :  33
Train Results (Loss and AUC):  0.5060792626424728 0.7321711599574096
Epoch-33 lr: 1.0000000000000002e-07 valid_loss: 0.5095207660410885
Epoch :  34
Train Results (Loss and AUC):  0.506097642566627 0.7319772832361537
Epoch-34 lr: 1.0000000000000002e-07 valid_loss: 0.509512186190332
Epoch :  35
Train Results (Loss and AUC):  0.5060848160542645 0.7320107425776314
Epoch-35 lr: 1.0000000000000002e-07 valid_loss: 0.5095279120223623
Epoch :  36
Train Results (Loss and AUC):  0.5062245537029981 0.7319931916770526
Epoch-36 lr: 1.0000000000000004e-08 valid_loss: 0.509516952603076
Epoch :  37
Train Results (Loss and AUC):  0.5062692988185635 0.7318032727091129
Epoch-37 lr: 1.0000000000000004e-08 valid_loss: 0.5095224895387748
Epoch :  38
Train Results (Loss and AUC):  0.5060381884077834 0.7320956976696255
Epoch-38 lr: 1.0000000000000004e-08 valid_loss: 0.5095274463785646
Epoch :  39
Train Results (Loss and AUC):  0.5061334847912491 0.7321152603496457
Epoch-39 lr: 1.0000000000000004e-08 valid_loss: 0.5095220742650994
Epoch :  40
Train Results (Loss and AUC):  0.5061175098337751 0.7317101283398444
Epoch-40 lr: 1.0000000000000004e-08 valid_loss: 0.5095040130783135
Epoch :  41
Train Results (Loss and AUC):  0.5060845520457053 0.7319743121736347
Epoch-41 lr: 1.0000000000000004e-08 valid_loss: 0.5095194362698586
Epoch :  42
Train Results (Loss and AUC):  0.5061897582103563 0.7318803642916372
Epoch-42 lr: 1.0000000000000004e-08 valid_loss: 0.5095101663484259
Epoch :  43
Train Results (Loss and AUC):  0.5064715340786182 0.7320821047394913
Epoch-43 lr: 1.0000000000000004e-08 valid_loss: 0.5095169622573494
Epoch :  44
Train Results (Loss and AUC):  0.506353242307445 0.7318884626601214
Epoch-44 lr: 1.0000000000000004e-08 valid_loss: 0.5095218610315816
Epoch :  45
Train Results (Loss and AUC):  0.5061266007707032 0.7321760862724309
Epoch-45 lr: 1.0000000000000004e-08 valid_loss: 0.5095119994011283
Epoch :  46
Train Results (Loss and AUC):  0.5061501416918527 0.7319177230656408
Epoch-46 lr: 1.0000000000000004e-08 valid_loss: 0.509516113101037
Epoch :  47
Train Results (Loss and AUC):  0.5063796756685973 0.731828429211893
Epoch-47 lr: 1.0000000000000004e-08 valid_loss: 0.5095180529104152
Epoch :  48
Train Results (Loss and AUC):  0.5058980079014535 0.7321874746502983
Epoch-48 lr: 1.0000000000000004e-08 valid_loss: 0.5095272497951705
Epoch :  49
Train Results (Loss and AUC):  0.5061953559921544 0.7319136741342385
Epoch-49 lr: 1.0000000000000004e-08 valid_loss: 0.5095191378268837
Epoch :  50
Train Results (Loss and AUC):  0.5062564642676476 0.7318275315873479
Epoch-50 lr: 1.0000000000000004e-08 valid_loss: 0.5095298929673405
Epoch :  51
Train Results (Loss and AUC):  0.5063451906957952 0.7318164263756725
Epoch-51 lr: 1.0000000000000004e-08 valid_loss: 0.5095303054426757
Epoch :  52
Train Results (Loss and AUC):  0.5061453867646634 0.7320488405479608
Epoch-52 lr: 1.0000000000000004e-08 valid_loss: 0.5095288375733604
Epoch :  53
Train Results (Loss and AUC):  0.5062395315639262 0.7320148411414642
Epoch-53 lr: 1.0000000000000004e-08 valid_loss: 0.5095257922797136
Epoch :  54
Train Results (Loss and AUC):  0.506246803049766 0.7319635278891851
Epoch-54 lr: 1.0000000000000004e-08 valid_loss: 0.5095298784159719
Epoch :  55
Train Results (Loss and AUC):  0.5061764858917578 0.7317816572283699
Epoch-55 lr: 1.0000000000000004e-08 valid_loss: 0.5095289542641438
Epoch :  56
Train Results (Loss and AUC):  0.5063549014789056 0.73176454912228
Epoch-56 lr: 1.0000000000000004e-08 valid_loss: 0.5095273694242111
Epoch :  57
Train Results (Loss and AUC):  0.5060170689165522 0.7317798526352127
Epoch-57 lr: 1.0000000000000004e-08 valid_loss: 0.5095496116109857
Epoch :  58
Train Results (Loss and AUC):  0.5060868851919478 0.7322193069519449
Epoch-58 lr: 1.0000000000000004e-08 valid_loss: 0.5095395093232813
Epoch :  59
Train Results (Loss and AUC):  0.50637846153111 0.7319024595353125
Epoch-59 lr: 1.0000000000000004e-08 valid_loss: 0.5095350736743408
Epoch :  60
Train Results (Loss and AUC):  0.5063171424278803 0.7316658959316044
Epoch-60 lr: 1.0000000000000004e-08 valid_loss: 0.5095283099463288
Epoch :  61
Train Results (Loss and AUC):  0.5060908022842362 0.7319253531634492
Epoch-61 lr: 1.0000000000000004e-08 valid_loss: 0.509532565941833
Epoch :  62
Train Results (Loss and AUC):  0.5058803626800173 0.7323044031047946
Epoch-62 lr: 1.0000000000000004e-08 valid_loss: 0.5095388112773358
Epoch :  63
Train Results (Loss and AUC):  0.5063981765922866 0.731766857972374
Epoch-63 lr: 1.0000000000000004e-08 valid_loss: 0.5095269471546854
Epoch :  64
Train Results (Loss and AUC):  0.5061704363362387 0.7321533149239889
Epoch-64 lr: 1.0000000000000004e-08 valid_loss: 0.5095437461501556
Epoch :  65
Train Results (Loss and AUC):  0.5061318989145461 0.7320025146591094
Epoch-65 lr: 1.0000000000000004e-08 valid_loss: 0.509542445061912
Epoch :  66
Train Results (Loss and AUC):  0.506225123878643 0.7319860000569457
Epoch-66 lr: 1.0000000000000004e-08 valid_loss: 0.5095376004355614
Epoch :  67
Train Results (Loss and AUC):  0.5064788683634625 0.7316625046899352
Epoch-67 lr: 1.0000000000000004e-08 valid_loss: 0.5095368839205711
Epoch :  68
Train Results (Loss and AUC):  0.5062990633702812 0.7318201567781208
Epoch-68 lr: 1.0000000000000004e-08 valid_loss: 0.5095298245479244
Epoch :  69
Train Results (Loss and AUC):  0.5059273361598083 0.7325149070033427
Epoch-69 lr: 1.0000000000000004e-08 valid_loss: 0.5095346526640682
Epoch :  70
Train Results (Loss and AUC):  0.5063607568454406 0.7322132402621232
Epoch-70 lr: 1.0000000000000004e-08 valid_loss: 0.5095427947145112
Epoch :  71
Train Results (Loss and AUC):  0.5060538813840374 0.7318757824694108
Epoch-71 lr: 1.0000000000000004e-08 valid_loss: 0.5095370718291108
Epoch :  72
Train Results (Loss and AUC):  0.5061119440306764 0.7319833213581454
Epoch-72 lr: 1.0000000000000004e-08 valid_loss: 0.5095588931455298
Epoch :  73
Train Results (Loss and AUC):  0.5060325956807962 0.7318992837169696
Epoch-73 lr: 1.0000000000000004e-08 valid_loss: 0.5095387881910297
Epoch :  74
Train Results (Loss and AUC):  0.5061657389777288 0.7320370927119904
Epoch-74 lr: 1.0000000000000004e-08 valid_loss: 0.509525564214993
Epoch :  75
Train Results (Loss and AUC):  0.5062384270877524 0.7319555551752507
Epoch-75 lr: 1.0000000000000004e-08 valid_loss: 0.5095456488815272
Epoch :  76
Train Results (Loss and AUC):  0.5064327778257386 0.7319609111434722
Epoch-76 lr: 1.0000000000000004e-08 valid_loss: 0.5095482559551096
Epoch :  77
Train Results (Loss and AUC):  0.5060611759675546 0.7319903356670588
Epoch-77 lr: 1.0000000000000004e-08 valid_loss: 0.5095375411107507
Epoch :  78
Train Results (Loss and AUC):  0.5061487848261641 0.7318681214379601
Epoch-78 lr: 1.0000000000000004e-08 valid_loss: 0.5095530012403855
Epoch :  79
Train Results (Loss and AUC):  0.5061998927551108 0.7317244234776584
Epoch-79 lr: 1.0000000000000004e-08 valid_loss: 0.5095338303718209
Epoch :  80
Train Results (Loss and AUC):  0.5062068907897239 0.7319039395172613
Epoch-80 lr: 1.0000000000000004e-08 valid_loss: 0.5095486201590775
Epoch :  81
Train Results (Loss and AUC):  0.5064409641972419 0.7320279890894433
Epoch-81 lr: 1.0000000000000004e-08 valid_loss: 0.5095266762753607
Epoch :  82
Train Results (Loss and AUC):  0.5059882351871935 0.7320903257034734
Epoch-82 lr: 1.0000000000000004e-08 valid_loss: 0.5095312938164097
Epoch :  83
Train Results (Loss and AUC):  0.5061075320583631 0.7319018993902455
Epoch-83 lr: 1.0000000000000004e-08 valid_loss: 0.5095504095576738
Epoch :  84
Train Results (Loss and AUC):  0.5062266612432028 0.7320507631404198
Epoch-84 lr: 1.0000000000000004e-08 valid_loss: 0.5095535735009422
Epoch :  85
Train Results (Loss and AUC):  0.5063740199670915 0.7318665990624299
Epoch-85 lr: 1.0000000000000004e-08 valid_loss: 0.5095147032972792
Epoch :  86
Train Results (Loss and AUC):  0.5060768667323289 0.7320657750026488
Epoch-86 lr: 1.0000000000000004e-08 valid_loss: 0.5095478674055824
Epoch :  87
Train Results (Loss and AUC):  0.50619018492064 0.7317606277142683
Epoch-87 lr: 1.0000000000000004e-08 valid_loss: 0.5095288444292937
Epoch :  88
Train Results (Loss and AUC):  0.5060952934485864 0.7320202428298842
Epoch-88 lr: 1.0000000000000004e-08 valid_loss: 0.5095527440729276
Epoch :  89
Train Results (Loss and AUC):  0.5065203372946336 0.731833100095245
Epoch-89 lr: 1.0000000000000004e-08 valid_loss: 0.5095393861963156
Epoch :  90
Train Results (Loss and AUC):  0.5060625852769058 0.7322007832439023
Epoch-90 lr: 1.0000000000000004e-08 valid_loss: 0.5095395622119098
Epoch :  91
Train Results (Loss and AUC):  0.5060963795308652 0.7321579674714154
Epoch-91 lr: 1.0000000000000004e-08 valid_loss: 0.509542618698917
Epoch :  92
Train Results (Loss and AUC):  0.5062825633794314 0.7317729769824088
Epoch-92 lr: 1.0000000000000004e-08 valid_loss: 0.509545472865933
Epoch :  93
Train Results (Loss and AUC):  0.5061297112345274 0.7320778414784315
Epoch-93 lr: 1.0000000000000004e-08 valid_loss: 0.50955021857096
Epoch :  94
Train Results (Loss and AUC):  0.5059504551095592 0.7321686504486421
Epoch-94 lr: 1.0000000000000004e-08 valid_loss: 0.5095378935616901
Epoch :  95
Train Results (Loss and AUC):  0.5063708340672357 0.7318236656638435
Epoch-95 lr: 1.0000000000000004e-08 valid_loss: 0.5095525311192436
Epoch :  96
Train Results (Loss and AUC):  0.5063570834020563 0.7318841676384857
Epoch-96 lr: 1.0000000000000004e-08 valid_loss: 0.5095392969292654
Epoch :  97
Train Results (Loss and AUC):  0.5061454467554396 0.732185235453946
Epoch-97 lr: 1.0000000000000004e-08 valid_loss: 0.5095397483015285
Epoch :  98
Train Results (Loss and AUC):  0.5063895690567501 0.7318632088333934
Epoch-98 lr: 1.0000000000000004e-08 valid_loss: 0.5095422543550321
Epoch :  99
Train Results (Loss and AUC):  0.5063381416216335 0.7321188857847666
Epoch-99 lr: 1.0000000000000004e-08 valid_loss: 0.5095524671771716
Epoch :  100
Train Results (Loss and AUC):  0.506408631626091 0.7317829001151765
Epoch-100 lr: 1.0000000000000004e-08 valid_loss: 0.5095409539663736
Sei(
  (lconv1): Sequential(
    (0): Conv1d(4, 480, kernel_size=(9,), stride=(1,), padding=(4,))
    (1): Conv1d(480, 480, kernel_size=(9,), stride=(1,), padding=(4,))
  )
  (conv1): Sequential(
    (0): Conv1d(480, 480, kernel_size=(9,), stride=(1,), padding=(4,))
    (1): ReLU(inplace=True)
    (2): Conv1d(480, 480, kernel_size=(9,), stride=(1,), padding=(4,))
    (3): ReLU(inplace=True)
  )
  (lconv2): Sequential(
    (0): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)
    (1): Dropout(p=0.2, inplace=False)
    (2): Conv1d(480, 640, kernel_size=(9,), stride=(1,), padding=(4,))
    (3): Conv1d(640, 640, kernel_size=(9,), stride=(1,), padding=(4,))
  )
  (conv2): Sequential(
    (0): Dropout(p=0.2, inplace=False)
    (1): Conv1d(640, 640, kernel_size=(9,), stride=(1,), padding=(4,))
    (2): ReLU(inplace=True)
    (3): Conv1d(640, 640, kernel_size=(9,), stride=(1,), padding=(4,))
    (4): ReLU(inplace=True)
  )
  (dconv1): Sequential(
    (0): Dropout(p=0.1, inplace=False)
    (1): Conv1d(640, 640, kernel_size=(5,), stride=(1,), padding=(4,), dilation=(2,))
    (2): ReLU(inplace=True)
  )
  (dconv2): Sequential(
    (0): Dropout(p=0.1, inplace=False)
    (1): Conv1d(640, 640, kernel_size=(5,), stride=(1,), padding=(8,), dilation=(4,))
    (2): ReLU(inplace=True)
  )
  (dconv3): Sequential(
    (0): Dropout(p=0.1, inplace=False)
    (1): Conv1d(640, 640, kernel_size=(5,), stride=(1,), padding=(16,), dilation=(8,))
    (2): ReLU(inplace=True)
  )
  (dconv4): Sequential(
    (0): Dropout(p=0.1, inplace=False)
    (1): Conv1d(640, 640, kernel_size=(5,), stride=(1,), padding=(32,), dilation=(16,))
    (2): ReLU(inplace=True)
  )
  (spline_tr): Sequential(
    (0): Dropout(p=0.5, inplace=False)
    (1): BSplineTransformation()
  )
  (classifier): Sequential(
    (0): Linear(in_features=10240, out_features=36, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=36, out_features=36, bias=True)
  )
)
Test Loss: 0.507 and AUC: 0.73 

