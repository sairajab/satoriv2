/s/chromatin/p/nobackup/Saira/original/satori/data/Arabidopsis_ChromAccessibility/atAll_m200_s600 36
Loaded model for finetunig... 0.43269882949305255
Epoch :  1
/s/chromatin/a/nobackup/Saira/anaconda3/envs/venv3/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Applied workaround for CuDNN issue, install nvrtc.so (Triggered internally at /opt/conda/conda-bld/pytorch_1704987296916/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:80.)
  return F.conv1d(input, weight, bias, self.stride,
Train Results (Loss and AUC):  0.6153494473129897 0.6029058402880447
Best Validation Loss: 0.825 and AUC: 0.58 

Epoch-1 lr: 0.005 valid_loss: 0.8248468259690513
Epoch :  2
Train Results (Loss and AUC):  0.5363429772839811 0.6891639046096955
Best Validation Loss: 0.538 and AUC: 0.69 

Epoch-2 lr: 0.005 valid_loss: 0.5379446213234198
Epoch :  3
Train Results (Loss and AUC):  0.521784389924666 0.7173145241078598
Epoch-3 lr: 0.005 valid_loss: 0.6074508448161989
Epoch :  4
Train Results (Loss and AUC):  0.5080066165668523 0.7417062731495941
Best Validation Loss: 0.511 and AUC: 0.74 

Epoch-4 lr: 0.005 valid_loss: 0.510603216192532
Epoch :  5
Train Results (Loss and AUC):  0.49669786975296704 0.7593620981348096
Epoch-5 lr: 0.005 valid_loss: 0.7226715759492256
Epoch :  6
Train Results (Loss and AUC):  0.48937821047746954 0.7693689970633408
Epoch-6 lr: 0.005 valid_loss: 0.7512723252247197
Epoch :  7
Train Results (Loss and AUC):  0.48160236329717826 0.779195899083277
Epoch-7 lr: 0.005 valid_loss: 0.5175486230794253
Epoch :  8
Train Results (Loss and AUC):  0.4751279382879799 0.7869377190895932
Epoch-8 lr: 0.005 valid_loss: 1.2039483223162906
Epoch :  9
Train Results (Loss and AUC):  0.47281609768721466 0.7898975504474574
Epoch-9 lr: 0.005 valid_loss: 0.6363192550453222
Epoch :  10
Train Results (Loss and AUC):  0.4665290193788014 0.7971201269495696
Epoch-10 lr: 0.005 valid_loss: 0.7136975579978155
Epoch :  11
Train Results (Loss and AUC):  0.46269743472723857 0.8010654020690253
Best Validation Loss: 0.504 and AUC: 0.79 

Epoch-11 lr: 0.005 valid_loss: 0.5044667690012936
Epoch :  12
Train Results (Loss and AUC):  0.4592721642327393 0.8050015264984386
Best Validation Loss: 0.501 and AUC: 0.80 

Epoch-12 lr: 0.005 valid_loss: 0.5012281292201208
Epoch :  13
Train Results (Loss and AUC):  0.4567727249980113 0.8078094208897183
Epoch-13 lr: 0.005 valid_loss: 0.5683345651962388
Epoch :  14
Train Results (Loss and AUC):  0.4539236530959957 0.8111021060193853
Best Validation Loss: 0.490 and AUC: 0.80 

Epoch-14 lr: 0.005 valid_loss: 0.49017904761811376
Epoch :  15
Train Results (Loss and AUC):  0.45223661477911176 0.8127269185152752
Epoch-15 lr: 0.005 valid_loss: 0.7927675138057118
Epoch :  16
Train Results (Loss and AUC):  0.45308169799783343 0.812842096448879
Epoch-16 lr: 0.005 valid_loss: 0.6288956980190367
Epoch :  17
Train Results (Loss and AUC):  0.44614349809355675 0.818880369957807
Best Validation Loss: 0.454 and AUC: 0.82 

Epoch-17 lr: 0.005 valid_loss: 0.45354829749590914
Epoch :  18
Train Results (Loss and AUC):  0.44449225843865403 0.8204959152902722
Epoch-18 lr: 0.005 valid_loss: 2.011416049630429
Epoch :  19
Train Results (Loss and AUC):  0.4461112075405211 0.8203370888169073
Epoch-19 lr: 0.005 valid_loss: 0.454617483794969
Epoch :  20
Train Results (Loss and AUC):  0.4413516735932291 0.8236087317561069
Epoch-20 lr: 0.005 valid_loss: 0.46243267202041516
Epoch :  21
Train Results (Loss and AUC):  0.43950399805575574 0.8253996090833774
Epoch-21 lr: 0.005 valid_loss: 0.5422888799732279
Epoch :  22
Train Results (Loss and AUC):  0.4378950300289689 0.826727479681615
Epoch-22 lr: 0.005 valid_loss: 0.506207244916701
Epoch :  23
Train Results (Loss and AUC):  0.43741999410347326 0.827468339282875
Epoch-23 lr: 0.005 valid_loss: 0.47755887516787354
Epoch :  24
Train Results (Loss and AUC):  0.43468373806793925 0.8300842840828024
Epoch-24 lr: 0.005 valid_loss: 1.479232045966135
Epoch :  25
Train Results (Loss and AUC):  0.43664121575153336 0.8294778840780751
Epoch-25 lr: 0.005 valid_loss: 0.6067128096108145
Epoch :  26
Train Results (Loss and AUC):  0.43117262087806235 0.8328235490941104
Best Validation Loss: 0.447 and AUC: 0.83 

Epoch-26 lr: 0.005 valid_loss: 0.4467699243708955
Epoch :  27
Train Results (Loss and AUC):  0.43090411076416535 0.8331486946723489
Epoch-27 lr: 0.005 valid_loss: 0.5344595259903742
Epoch :  28
Train Results (Loss and AUC):  0.4285478533648209 0.835189190661913
Epoch-28 lr: 0.005 valid_loss: 0.4787851702159559
Epoch :  29
Train Results (Loss and AUC):  0.42743673320372616 0.8364126575494606
Epoch-29 lr: 0.005 valid_loss: 0.987715504818679
Epoch :  30
Train Results (Loss and AUC):  0.42726597972696884 0.8365127777725966
Epoch-30 lr: 0.005 valid_loss: 1.4711614337885324
Epoch :  31
Train Results (Loss and AUC):  0.4327878075508122 0.8346635469768886
Epoch-31 lr: 0.005 valid_loss: 0.5111215390230008
Epoch :  32
Train Results (Loss and AUC):  0.4254122319224305 0.8379531797919266
Epoch-32 lr: 0.005 valid_loss: 0.46381760664948835
Epoch :  33
Train Results (Loss and AUC):  0.42300587787223787 0.8400394460503058
Epoch-33 lr: 0.005 valid_loss: 0.4857452120019796
Epoch :  34
Train Results (Loss and AUC):  0.4215930803855541 0.8411313314703626
Epoch-34 lr: 0.005 valid_loss: 0.5282040662328962
Epoch :  35
Train Results (Loss and AUC):  0.41943631615178184 0.8430745860459093
Best Validation Loss: 0.446 and AUC: 0.84 

Epoch-35 lr: 0.005 valid_loss: 0.44553919045578144
Epoch :  36
Train Results (Loss and AUC):  0.42044499484894554 0.8423802685804247
Epoch-36 lr: 0.005 valid_loss: 0.7600128586303461
Epoch :  37
Train Results (Loss and AUC):  0.41996677548079386 0.8427425060300543
Epoch-37 lr: 0.005 valid_loss: 0.6705534211906469
Epoch :  38
Train Results (Loss and AUC):  0.41852978384396494 0.8439405699124691
Epoch-38 lr: 0.005 valid_loss: 0.47343618825008055
Epoch :  39
Train Results (Loss and AUC):  0.4168333066155689 0.8453671261497261
Epoch-39 lr: 0.005 valid_loss: 0.47645763052461293
Epoch :  40
Train Results (Loss and AUC):  0.4155426789228711 0.8464104018116854
Epoch-40 lr: 0.005 valid_loss: 0.48066759011555166
Epoch :  41
Train Results (Loss and AUC):  0.41394437191343136 0.847843222542919
Best Validation Loss: 0.441 and AUC: 0.84 

Epoch-41 lr: 0.005 valid_loss: 0.44062122954449184
Epoch :  42
Train Results (Loss and AUC):  0.41383175897654434 0.8479751089737534
Epoch-42 lr: 0.005 valid_loss: 0.5375999591440103
Epoch :  43
Train Results (Loss and AUC):  0.41416288938623436 0.8479713140397366
Epoch-43 lr: 0.005 valid_loss: 0.7973445813420793
Epoch :  44
Train Results (Loss and AUC):  0.4141443393887564 0.848068165174448
Best Validation Loss: 0.440 and AUC: 0.84 

Epoch-44 lr: 0.005 valid_loss: 0.44000185613341175
Epoch :  45
Train Results (Loss and AUC):  0.40980568226290814 0.8510112370386763
Epoch-45 lr: 0.005 valid_loss: 0.44948269014067493
Epoch :  46
Train Results (Loss and AUC):  0.40938195838945074 0.8516231752575464
Epoch-46 lr: 0.005 valid_loss: 0.4466956250824279
Epoch :  47
Train Results (Loss and AUC):  0.40849215087115553 0.8524091926813377
Epoch-47 lr: 0.005 valid_loss: 0.700066969428264
Epoch :  48
Train Results (Loss and AUC):  0.40772618720191667 0.8528696469564674
Epoch-48 lr: 0.005 valid_loss: 0.4515771916214849
Epoch :  49
Train Results (Loss and AUC):  0.40684702388670196 0.8535512420172409
Epoch-49 lr: 0.005 valid_loss: 0.45693761292197893
Epoch :  50
Train Results (Loss and AUC):  0.4064138398294033 0.8538812801245353
Epoch-50 lr: 0.005 valid_loss: 0.445004339089416
Sei(
  (lconv1): Sequential(
    (0): Conv1d(4, 480, kernel_size=(9,), stride=(1,), padding=(4,))
    (1): Conv1d(480, 480, kernel_size=(9,), stride=(1,), padding=(4,))
  )
  (conv1): Sequential(
    (0): Conv1d(480, 480, kernel_size=(9,), stride=(1,), padding=(4,))
    (1): ReLU(inplace=True)
    (2): Conv1d(480, 480, kernel_size=(9,), stride=(1,), padding=(4,))
    (3): ReLU(inplace=True)
  )
  (lconv2): Sequential(
    (0): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)
    (1): Dropout(p=0.2, inplace=False)
    (2): Conv1d(480, 640, kernel_size=(9,), stride=(1,), padding=(4,))
    (3): Conv1d(640, 640, kernel_size=(9,), stride=(1,), padding=(4,))
  )
  (conv2): Sequential(
    (0): Dropout(p=0.2, inplace=False)
    (1): Conv1d(640, 640, kernel_size=(9,), stride=(1,), padding=(4,))
    (2): ReLU(inplace=True)
    (3): Conv1d(640, 640, kernel_size=(9,), stride=(1,), padding=(4,))
    (4): ReLU(inplace=True)
  )
  (dconv1): Sequential(
    (0): Dropout(p=0.1, inplace=False)
    (1): Conv1d(640, 640, kernel_size=(5,), stride=(1,), padding=(4,), dilation=(2,))
    (2): ReLU(inplace=True)
  )
  (dconv2): Sequential(
    (0): Dropout(p=0.1, inplace=False)
    (1): Conv1d(640, 640, kernel_size=(5,), stride=(1,), padding=(8,), dilation=(4,))
    (2): ReLU(inplace=True)
  )
  (dconv3): Sequential(
    (0): Dropout(p=0.1, inplace=False)
    (1): Conv1d(640, 640, kernel_size=(5,), stride=(1,), padding=(16,), dilation=(8,))
    (2): ReLU(inplace=True)
  )
  (dconv4): Sequential(
    (0): Dropout(p=0.1, inplace=False)
    (1): Conv1d(640, 640, kernel_size=(5,), stride=(1,), padding=(32,), dilation=(16,))
    (2): ReLU(inplace=True)
  )
  (spline_tr): Sequential(
    (0): Dropout(p=0.5, inplace=False)
    (1): BSplineTransformation()
  )
  (classifier): Sequential(
    (0): Linear(in_features=10240, out_features=36, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=36, out_features=36, bias=True)
  )
)
Test Loss: 0.444 and AUC: 0.84 

